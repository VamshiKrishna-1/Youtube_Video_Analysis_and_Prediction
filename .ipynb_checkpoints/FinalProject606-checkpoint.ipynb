{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284fe48e",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6daace5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in c:\\users\\timbe\\anaconda3\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: click in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from opendatasets) (4.64.1)\n",
      "Requirement already satisfied: kaggle in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from opendatasets) (1.5.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from click->opendatasets) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2022.9.14)\n",
      "Requirement already satisfied: requests in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.28.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da558223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\timbe\\anaconda3\\lib\\site-packages (2.80.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.11.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.16.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.58.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.22.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1712b07a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth-oauthlib in c:\\users\\timbe\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth-oauthlib) (1.3.1)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth-oauthlib) (2.16.2)\n",
      "Requirement already satisfied: six in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth-httplib2) (1.16.0)\n",
      "Requirement already satisfied: httplib2>=0.15.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth-httplib2) (0.21.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from httplib2>=0.15.0->google-auth-httplib2) (3.0.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.28.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-auth-oauthlib google-auth-httplib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05450e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting isodate\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.7/41.7 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\timbe\\anaconda3\\lib\\site-packages (from isodate) (1.16.0)\n",
      "Installing collected packages: isodate\n",
      "Successfully installed isodate-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install isodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d6298e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'isodate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24344\\65814962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0misodate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'isodate'"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import plotly.express as px\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from IPython.display import JSON\n",
    "import isodate\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dec60e",
   "metadata": {},
   "source": [
    "### Loading the dataset from the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a51d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'https://www.kaggle.com/datasets/rsrishav/youtube-trending-video-dataset?select=US_youtube_trending_data.csv'\n",
    "\n",
    "final_dir = '\\\\'.join(os.getcwd().split('\\\\')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b76e40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"C:\\Users\\timbe\\Final Project\\youtube-trending-video-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(dataset, data_dir=final_dir)\n",
    "\n",
    "final_dir += '\\\\youtube-trending-video-dataset\\\\US_youtube_trending_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd454e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3C66w5Z0ixs</td>\n",
       "      <td>I ASKED HER TO BE MY GIRLFRIEND...</td>\n",
       "      <td>2020-08-11T19:20:14Z</td>\n",
       "      <td>UCvtRTOMP2TqYqu51xNrqAzg</td>\n",
       "      <td>Brawadis</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>brawadis|prank|basketball|skits|ghost|funny vi...</td>\n",
       "      <td>1514614</td>\n",
       "      <td>156908</td>\n",
       "      <td>5855</td>\n",
       "      <td>35313</td>\n",
       "      <td>https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M9Pmf9AB4Mo</td>\n",
       "      <td>Apex Legends | Stories from the Outlands – “Th...</td>\n",
       "      <td>2020-08-11T17:00:10Z</td>\n",
       "      <td>UC0ZV6M2THA81QT9hrVWJG3A</td>\n",
       "      <td>Apex Legends</td>\n",
       "      <td>20</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>Apex Legends|Apex Legends characters|new Apex ...</td>\n",
       "      <td>2381688</td>\n",
       "      <td>146739</td>\n",
       "      <td>2794</td>\n",
       "      <td>16549</td>\n",
       "      <td>https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>While running her own modding shop, Ramya Pare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J78aPJ3VyNs</td>\n",
       "      <td>I left youtube for a month and THIS is what ha...</td>\n",
       "      <td>2020-08-11T16:34:06Z</td>\n",
       "      <td>UCYzPXprvl5Y-Sf0g4vX-m6g</td>\n",
       "      <td>jacksepticeye</td>\n",
       "      <td>24</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>jacksepticeye|funny|funny meme|memes|jacksepti...</td>\n",
       "      <td>2038853</td>\n",
       "      <td>353787</td>\n",
       "      <td>2628</td>\n",
       "      <td>40221</td>\n",
       "      <td>https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I left youtube for a month and this is what ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  3C66w5Z0ixs                 I ASKED HER TO BE MY GIRLFRIEND...   \n",
       "1  M9Pmf9AB4Mo  Apex Legends | Stories from the Outlands – “Th...   \n",
       "2  J78aPJ3VyNs  I left youtube for a month and THIS is what ha...   \n",
       "\n",
       "            publishedAt                 channelId   channelTitle  categoryId  \\\n",
       "0  2020-08-11T19:20:14Z  UCvtRTOMP2TqYqu51xNrqAzg       Brawadis          22   \n",
       "1  2020-08-11T17:00:10Z  UC0ZV6M2THA81QT9hrVWJG3A   Apex Legends          20   \n",
       "2  2020-08-11T16:34:06Z  UCYzPXprvl5Y-Sf0g4vX-m6g  jacksepticeye          24   \n",
       "\n",
       "          trending_date                                               tags  \\\n",
       "0  2020-08-12T00:00:00Z  brawadis|prank|basketball|skits|ghost|funny vi...   \n",
       "1  2020-08-12T00:00:00Z  Apex Legends|Apex Legends characters|new Apex ...   \n",
       "2  2020-08-12T00:00:00Z  jacksepticeye|funny|funny meme|memes|jacksepti...   \n",
       "\n",
       "   view_count   likes  dislikes  comment_count  \\\n",
       "0     1514614  156908      5855          35313   \n",
       "1     2381688  146739      2794          16549   \n",
       "2     2038853  353787      2628          40221   \n",
       "\n",
       "                                   thumbnail_link  comments_disabled  \\\n",
       "0  https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg              False   \n",
       "1  https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg              False   \n",
       "2  https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg              False   \n",
       "\n",
       "   ratings_disabled                                        description  \n",
       "0             False  SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...  \n",
       "1             False  While running her own modding shop, Ramya Pare...  \n",
       "2             False  I left youtube for a month and this is what ha...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(final_dir)\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa406005",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249d97da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185990, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the DataFrame\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9d684e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34066"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the unique video_ids in the `video_id` column\n",
    "data['video_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1901e",
   "metadata": {},
   "source": [
    "- There are only 34066 unique videos out of 185990 video ids.\n",
    "- That means videos keep repeating.\n",
    "- The combination of `video_id` and `trending_date` gives us the information about how many days a specific video have been trending.\n",
    "- Let's consider an example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a04af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401     2020-09-18T00:00:00Z\n",
       "7602     2020-09-19T00:00:00Z\n",
       "7806     2020-09-20T00:00:00Z\n",
       "8273     2020-09-22T00:00:00Z\n",
       "8722     2020-09-24T00:00:00Z\n",
       "8949     2020-09-25T00:00:00Z\n",
       "9132     2020-09-26T00:00:00Z\n",
       "9335     2020-09-27T00:00:00Z\n",
       "9528     2020-09-28T00:00:00Z\n",
       "9745     2020-09-29T00:00:00Z\n",
       "9965     2020-09-30T00:00:00Z\n",
       "10157    2020-10-01T00:00:00Z\n",
       "10339    2020-10-02T00:00:00Z\n",
       "10519    2020-10-03T00:00:00Z\n",
       "10731    2020-10-04T00:00:00Z\n",
       "10985    2020-10-05T00:00:00Z\n",
       "11191    2020-10-06T00:00:00Z\n",
       "11388    2020-10-07T00:00:00Z\n",
       "11577    2020-10-08T00:00:00Z\n",
       "11761    2020-10-09T00:00:00Z\n",
       "11958    2020-10-10T00:00:00Z\n",
       "12158    2020-10-11T00:00:00Z\n",
       "12380    2020-10-12T00:00:00Z\n",
       "12574    2020-10-13T00:00:00Z\n",
       "12787    2020-10-14T00:00:00Z\n",
       "13390    2020-10-17T00:00:00Z\n",
       "13587    2020-10-18T00:00:00Z\n",
       "Name: trending_date, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code shows an example of how a randomly chosen video_id has continuous trending_dates\n",
    "example_id = data['video_id'].value_counts().sort_values(ascending = False).index[np.random.randint(10,20)]\n",
    "\n",
    "data[data['video_id'] == example_id]['trending_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76637c0f",
   "metadata": {},
   "source": [
    "- In the above example we can see that a specific video has been trending for days.\n",
    "- That means we have to modify the data such that it only has unique video_id in `video_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01377521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_name</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>description</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video_id</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>publishedAt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>channelId</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>channelTitle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>categoryId</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trending_date</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tags</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>view_count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>likes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dislikes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>comment_count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>thumbnail_link</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>comments_disabled</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ratings_disabled</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column_name   Count  Percentage\n",
       "0         description  4048.0        2.18\n",
       "1            video_id     0.0        0.00\n",
       "2               title     0.0        0.00\n",
       "3         publishedAt     0.0        0.00\n",
       "4           channelId     0.0        0.00\n",
       "5        channelTitle     0.0        0.00\n",
       "6          categoryId     0.0        0.00\n",
       "7       trending_date     0.0        0.00\n",
       "8                tags     0.0        0.00\n",
       "9          view_count     0.0        0.00\n",
       "10              likes     0.0        0.00\n",
       "11           dislikes     0.0        0.00\n",
       "12      comment_count     0.0        0.00\n",
       "13     thumbnail_link     0.0        0.00\n",
       "14  comments_disabled     0.0        0.00\n",
       "15   ratings_disabled     0.0        0.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null values\n",
    "\n",
    "def null_values(df):\n",
    "    temp = df.isna().sum()\n",
    "    temp_1 = round(temp * 100 / df.shape[0], 2)\n",
    "    \n",
    "    return pd.DataFrame((temp, temp_1), index = ['Count', 'Percentage']).T.sort_values('Count', ascending = False)\n",
    "\n",
    "\n",
    "null_df = null_values(data).reset_index().rename({'index':'Column_name'}, axis =1)\n",
    "null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fc651",
   "metadata": {},
   "source": [
    "We can see that there are around 10% missing values in `description` column\n",
    "- We shall keep the `description` column as it is while analysis and do the null value treatment during model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a5c14",
   "metadata": {},
   "source": [
    "- Also we can observe that the data has certain important columns missing in it. Such as `Duration` and `Comments` of video.\n",
    "- Let's use `video_id` to extract the data from `YOUTUBE API`.\n",
    "- The link for the Youtube API is: https://developers.google.com/youtube/v3/quickstart/python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aad320",
   "metadata": {},
   "source": [
    "### Extracting `Duration` and `Comments` from Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "980bb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's get unique video ids from the video_id column in dataframe\n",
    "\n",
    "videos_list = data['video_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84a08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API_KEY is not displayed for security purposes\n",
    "\n",
    "api_key = \"*********************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6664c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fuction is used to extract 'Duration' and 'Comments' of a provided video_id\n",
    "\n",
    "def get_video_info(vid_id, api_key):\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "\n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, developerKey=api_key)\n",
    "\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics,status\",\n",
    "        id=vid_id\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    info_temp = []\n",
    "    info_temp.append(vid_id)\n",
    "    info_temp.append(response['items'][0]['contentDetails']['duration'])\n",
    "    info_temp.append(response['items'][0]['status']['madeForKids'])\n",
    "    \n",
    "    youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey = api_key)\n",
    "\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet,replies\",\n",
    "        videoId=vid_id,\n",
    "        textFormat = \"plainText\",\n",
    "        order = \"relevance\"\n",
    "    )\n",
    "    response_comments = request.execute()\n",
    "    \n",
    "    info_temp.append([response_comments['items'][i]['snippet']['topLevelComment']['snippet']['textOriginal'] for i in range(20)])\n",
    "    \n",
    "    \n",
    "    return info_temp\n",
    "\n",
    "\n",
    "\n",
    "# This function is used to create a dataframe from the list of video_ids in video_list and save it in the repository.\n",
    "# Start and end number is the range of video_ids you want the data for.\n",
    "\n",
    "def data_to_csv(videos_list, start_number, end_number):\n",
    "    print(\"Code Running\")\n",
    "    video_info = []\n",
    "    deleted_videos = []\n",
    "    \n",
    "    for vid_id in videos_list[start_number : end_number]:\n",
    "        try:\n",
    "            video_info.append(get_video_info(vid_id, api_key))\n",
    "        except:\n",
    "            deleted_videos.append(vid_id)\n",
    "    \n",
    "    print(\"Number of videos extracted =\", len(video_info))\n",
    "    print(\"Number of video deleted =\", len(deleted_videos))\n",
    "    \n",
    "    df = pd.DataFrame(video_info, columns = ['video_id', 'Duration', 'madeForKids', 'Comments'])\n",
    "    df.to_csv('./YoutubeDataFiles/Data_' + str(start_number) + '_' + str(end_number) + '.csv')\n",
    "    \n",
    "    \n",
    "# Saving the data to a .csv file by calling the funciton\n",
    "\n",
    "#data_to_csv(videos_list, 0, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa7fae",
   "metadata": {},
   "source": [
    "- Although it was possible to extract all the video_ids at once. It would cost money if you were to extract more than 5000.\n",
    "- Hence, we used different API_KEYS and various start & end_numbers to save the files in the repository.\n",
    "- The files are stored in `./YoutubeDataFiles` directory.\n",
    "- The .csv files follow the convention `Data_startnumber_endnumber.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6d588df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data_0_4000.csv',\n",
       " 'Data_14000_19000.csv',\n",
       " 'Data_4000_9000.csv',\n",
       " 'Data_9000_14000.csv']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[pd.read_csv(file_csv, columns = ['video_id', 'madeForKids', 'Comments']) for file_csv in os.listdir('./YoutubeDataFiles')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c09713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read the 'extracted files' in and merge them to merge with original Dataframe\n",
    "\n",
    "# extracted_df = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2538258",
   "metadata": {},
   "source": [
    "### Modifying the Original Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4ade860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3C66w5Z0ixs</td>\n",
       "      <td>I ASKED HER TO BE MY GIRLFRIEND...</td>\n",
       "      <td>2020-08-11T19:20:14Z</td>\n",
       "      <td>UCvtRTOMP2TqYqu51xNrqAzg</td>\n",
       "      <td>Brawadis</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>brawadis|prank|basketball|skits|ghost|funny vi...</td>\n",
       "      <td>1514614</td>\n",
       "      <td>156908</td>\n",
       "      <td>5855</td>\n",
       "      <td>35313</td>\n",
       "      <td>https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                               title           publishedAt  \\\n",
       "0  3C66w5Z0ixs  I ASKED HER TO BE MY GIRLFRIEND...  2020-08-11T19:20:14Z   \n",
       "\n",
       "                  channelId channelTitle  categoryId         trending_date  \\\n",
       "0  UCvtRTOMP2TqYqu51xNrqAzg     Brawadis          22  2020-08-12T00:00:00Z   \n",
       "\n",
       "                                                tags  view_count   likes  \\\n",
       "0  brawadis|prank|basketball|skits|ghost|funny vi...     1514614  156908   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      5855          35313  https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  \\\n",
       "0              False             False   \n",
       "\n",
       "                                         description  \n",
       "0  SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking column name and values in the dataframe\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eee1998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id             object\n",
       "title                object\n",
       "publishedAt          object\n",
       "channelId            object\n",
       "channelTitle         object\n",
       "categoryId            int64\n",
       "trending_date        object\n",
       "tags                 object\n",
       "view_count            int64\n",
       "likes                 int64\n",
       "dislikes              int64\n",
       "comment_count         int64\n",
       "thumbnail_link       object\n",
       "comments_disabled      bool\n",
       "ratings_disabled       bool\n",
       "description          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the datatypes of each column\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d4001a",
   "metadata": {},
   "source": [
    "Let's make the following changes to the Original Dataframe in 4 major steps:\n",
    "\n",
    "1. Drop `channelId` column as it is not necessary for the analysis and prediction.\n",
    "<br>\n",
    "\n",
    "1. Convert `publishedAt` and `trending_date` to Pandas_Datetime object. Map each category_id to respective category in `categroty_id` column. This is done using `US_category_id.json` file from the source file.\n",
    "<br>\n",
    "\n",
    "2. Groupby `video_id` column and apply the following functions to the rest of the columns:\n",
    "- `title` - <b>Function : MODE</b> - because title is same for each video_id.\n",
    "- `publishedAT` - <b>Function : MODE</b> - although published date is same for each video_id. Let's consider minimum value.\n",
    "- `channelTitle` - <b>Function : MODE</b> - because channel title is same for each video_id.\n",
    "- `categroryId` - <b>Function : MODE</b> - because categoryId is same for each video_id.\n",
    "- `trending_date` - <b>Function : [min(trending_date), max(trending_date)]</b> - this is because we can extract features like `How many days video took to trend` and `How many days the video have been trending`.\n",
    "- `tags` - <b>Function : MODE</b> - because tags are same for each video_id.\n",
    "- `likes` - <b>Function : [min(likes), max(likes)]</b> - this is because we can extract features like `How many likes have be increased during the period`.\n",
    "- `comments_disabled` - <b>Function : MODE</b> - because comments_disabled_flag is same for each video_id.\n",
    "- `ratings_disabled` - <b>Function : MODE</b> - because ratings_disabled_flag is same for each video_id.\n",
    "<br>\n",
    "<br>\n",
    "       \n",
    "4. Drop `dislikes` column as the dislikes has been discontinued from November 2021.\n",
    "Reference: https://www.google.com/search?q=when+did+youtube+remove+dislikes&rlz=1C1UEAD_enUS1037US1037&oq=when+did+youtube+remove+&aqs=chrome.0.0i512j69i57j0i512l6j0i22i30l2.6954j1j4&sourceid=chrome&ie=UTF-8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65300f01",
   "metadata": {},
   "source": [
    "#### Step - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7978bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3C66w5Z0ixs</td>\n",
       "      <td>I ASKED HER TO BE MY GIRLFRIEND...</td>\n",
       "      <td>2020-08-11T19:20:14Z</td>\n",
       "      <td>Brawadis</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>brawadis|prank|basketball|skits|ghost|funny vi...</td>\n",
       "      <td>1514614</td>\n",
       "      <td>156908</td>\n",
       "      <td>5855</td>\n",
       "      <td>35313</td>\n",
       "      <td>https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M9Pmf9AB4Mo</td>\n",
       "      <td>Apex Legends | Stories from the Outlands – “Th...</td>\n",
       "      <td>2020-08-11T17:00:10Z</td>\n",
       "      <td>Apex Legends</td>\n",
       "      <td>20</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>Apex Legends|Apex Legends characters|new Apex ...</td>\n",
       "      <td>2381688</td>\n",
       "      <td>146739</td>\n",
       "      <td>2794</td>\n",
       "      <td>16549</td>\n",
       "      <td>https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>While running her own modding shop, Ramya Pare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J78aPJ3VyNs</td>\n",
       "      <td>I left youtube for a month and THIS is what ha...</td>\n",
       "      <td>2020-08-11T16:34:06Z</td>\n",
       "      <td>jacksepticeye</td>\n",
       "      <td>24</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>jacksepticeye|funny|funny meme|memes|jacksepti...</td>\n",
       "      <td>2038853</td>\n",
       "      <td>353787</td>\n",
       "      <td>2628</td>\n",
       "      <td>40221</td>\n",
       "      <td>https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I left youtube for a month and this is what ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  3C66w5Z0ixs                 I ASKED HER TO BE MY GIRLFRIEND...   \n",
       "1  M9Pmf9AB4Mo  Apex Legends | Stories from the Outlands – “Th...   \n",
       "2  J78aPJ3VyNs  I left youtube for a month and THIS is what ha...   \n",
       "\n",
       "            publishedAt   channelTitle  categoryId         trending_date  \\\n",
       "0  2020-08-11T19:20:14Z       Brawadis          22  2020-08-12T00:00:00Z   \n",
       "1  2020-08-11T17:00:10Z   Apex Legends          20  2020-08-12T00:00:00Z   \n",
       "2  2020-08-11T16:34:06Z  jacksepticeye          24  2020-08-12T00:00:00Z   \n",
       "\n",
       "                                                tags  view_count   likes  \\\n",
       "0  brawadis|prank|basketball|skits|ghost|funny vi...     1514614  156908   \n",
       "1  Apex Legends|Apex Legends characters|new Apex ...     2381688  146739   \n",
       "2  jacksepticeye|funny|funny meme|memes|jacksepti...     2038853  353787   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      5855          35313  https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg   \n",
       "1      2794          16549  https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg   \n",
       "2      2628          40221  https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  \\\n",
       "0              False             False   \n",
       "1              False             False   \n",
       "2              False             False   \n",
       "\n",
       "                                         description  \n",
       "0  SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...  \n",
       "1  While running her own modding shop, Ramya Pare...  \n",
       "2  I left youtube for a month and this is what ha...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping channelId\n",
    "\n",
    "data.drop(['channelId'], axis = 1, inplace = True)\n",
    "\n",
    "# Validating the above code\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9b778",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Step - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f0419",
   "metadata": {},
   "source": [
    "- `publishedAt`, `trending_date` are object type. Let's convert it to Datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a1285b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publishedAt      datetime64[ns, UTC]\n",
       "trending_date    datetime64[ns, UTC]\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting 'publishedAt' and 'trending_date' to datetime objects\n",
    "\n",
    "data[['publishedAt', 'trending_date']] = data[['publishedAt', 'trending_date']].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "# Validating the above changes\n",
    "\n",
    "data.dtypes[['publishedAt', 'trending_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741d36a",
   "metadata": {},
   "source": [
    "We can see that `categoryId` column has id's of repective categories. We can access the description of categoryId from the `US_category_id.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eadd0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    People & Blogs\n",
       "1            Gaming\n",
       "2     Entertainment\n",
       "3             Music\n",
       "4     Howto & Style\n",
       "Name: categoryId, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's import US_category_id.json file and map the category id's respectively\n",
    "\n",
    "category_path = '\\\\'.join(final_dir.split('\\\\')[:-1]) + '\\\\US_category_id.json'\n",
    "\n",
    "\n",
    "# Creating a dictionary object which stores the category id and its respective category\n",
    "category_dict = {}\n",
    "\n",
    "with open(category_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "    for item in json_data['items']:\n",
    "        category_dict[int(item['id'])] = item['snippet']['title']\n",
    "    \n",
    "data['categoryId'] = data['categoryId'].apply(lambda x: category_dict[x])\n",
    "\n",
    "# Validating the above code\n",
    "data['categoryId'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecb7ad",
   "metadata": {},
   "source": [
    "#### Step - 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f18d2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--14w5SOEUs</td>\n",
       "      <td>Migos - Avalanche (Official Video)</td>\n",
       "      <td>2021-06-10 16:00:00+00:00</td>\n",
       "      <td>MigosVEVO</td>\n",
       "      <td>Music</td>\n",
       "      <td>[2021-06-11 00:00:00+00:00, 2021-06-15 00:00:0...</td>\n",
       "      <td>Migos|Avalanche|Quality|Control|Music/Motown|R...</td>\n",
       "      <td>[122830, 262692]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--2O86Z0hsM</td>\n",
       "      <td>MY TESLA PAYS FOR ITSELF</td>\n",
       "      <td>2022-03-09 23:19:08+00:00</td>\n",
       "      <td>jf.okay</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>[2022-03-11 00:00:00+00:00, 2022-03-15 00:00:0...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[16481, 17290]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                               title               publishedAt  \\\n",
       "0  --14w5SOEUs  Migos - Avalanche (Official Video) 2021-06-10 16:00:00+00:00   \n",
       "1  --2O86Z0hsM            MY TESLA PAYS FOR ITSELF 2022-03-09 23:19:08+00:00   \n",
       "\n",
       "  channelTitle     categoryId  \\\n",
       "0    MigosVEVO          Music   \n",
       "1      jf.okay  Entertainment   \n",
       "\n",
       "                                       trending_date  \\\n",
       "0  [2021-06-11 00:00:00+00:00, 2021-06-15 00:00:0...   \n",
       "1  [2022-03-11 00:00:00+00:00, 2022-03-15 00:00:0...   \n",
       "\n",
       "                                                tags             likes  \\\n",
       "0  Migos|Avalanche|Quality|Control|Music/Motown|R...  [122830, 262692]   \n",
       "1                                             [None]    [16481, 17290]   \n",
       "\n",
       "   comments_disabled  ratings_disabled  \n",
       "0              False             False  \n",
       "1              False             False  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function converts list to min_max_list as per conditions specified in the above cell\n",
    "\n",
    "def column_start_end(x: list) -> list:\n",
    "    return([min(x), max(x)])\n",
    "\n",
    "\n",
    "# Grouping by 'video_id' and aggregating using functions as specified in the above cell\n",
    "\n",
    "modified_df = data.groupby('video_id').agg({'title':st.mode, 'publishedAt':np.min, 'channelTitle':st.mode, 'categoryId':st.mode,\n",
    "              'trending_date': column_start_end, 'tags': st.mode, 'likes': column_start_end,\n",
    "                'comments_disabled': st.mode, 'ratings_disabled': st.mode}).reset_index()\n",
    "\n",
    "modified_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "167e7ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34066, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5ef9f",
   "metadata": {},
   "source": [
    "The resulting dataframe has 34066 rows and 10 columns.\n",
    "\n",
    "Let's make the following changes to the resulting dataframe in 7 steps:\n",
    "1. Create new columns `trending_date_start` & `trending_date_end` from `trending_date` column.\n",
    "2. Create new columns `likes_start` & `likes_end` from `likes` column.\n",
    "3. `tags` have `[None]` values in it. Converting them to Null values.\n",
    "4. Create new column `tagsCount` from `tags` column. Which indicates the number of tags used in particular video.\n",
    "5. Create new column `hoursTakenToTrend` from `trending_date_start` & `publishedAt` columns.\n",
    "6. Create new column `trendingDaysDuration` from `trending_date_end` & `trending_date_start` columns.\n",
    "7. Drop columns `trending_date`, `likes`, `publishedAt` as they are no longer required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab0ab5",
   "metadata": {},
   "source": [
    "#### Step - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe98d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns trending_date_start & trending_date_end from trending_date column.\n",
    "\n",
    "modified_df['trending_date_start'] = modified_df['trending_date'].apply(lambda x: min(x))\n",
    "modified_df['trending_date_end'] = modified_df['trending_date'].apply(lambda x: max(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f91677",
   "metadata": {},
   "source": [
    "#### Step - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da5a6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns likes_start & likes_end from likes column.\n",
    "\n",
    "modified_df['likes_start'] = modified_df['likes'].apply(lambda x: min(x))\n",
    "modified_df['likes_end'] = modified_df['likes'].apply(lambda x: max(x))\n",
    "# df.drop('likes', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9d739",
   "metadata": {},
   "source": [
    "#### Step - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c35f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags have [None] values in it. Converting them to Null values.\n",
    "\n",
    "modified_df['tags'] = modified_df['tags'].apply(lambda x: x if x!= '[None]' else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7eefc8",
   "metadata": {},
   "source": [
    "#### Step - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67f49f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column tagsCount from tags column. Which indicates the number of tags used in particular video.\n",
    "\n",
    "modified_df['tagCount'] = modified_df['tags'].apply(lambda x: 0 if type(x) == float else len(list(x.split('|'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f9549",
   "metadata": {},
   "source": [
    "#### Step - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40275390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column hoursTakenToTrend from trending_date_start & publishedAt columns.\n",
    "\n",
    "modified_df['hoursTakenToTrend'] = round((modified_df['trending_date_start'] - modified_df['publishedAt']).dt.seconds/(60*60), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0026e9",
   "metadata": {},
   "source": [
    "#### Step - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4ae5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column trendingDaysDuration from trending_date_end & trending_date_start columns.\n",
    "\n",
    "modified_df['trendingDaysDuration'] = (modified_df['trending_date_end'] - modified_df['trending_date_start']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf83ad",
   "metadata": {},
   "source": [
    "#### Step - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bebfdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns trending_date, likes, publishedAt as they are no longer required.\n",
    "\n",
    "modified_df.drop(['trending_date', 'likes', 'publishedAt'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b651c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>tags</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>trending_date_start</th>\n",
       "      <th>trending_date_end</th>\n",
       "      <th>likes_start</th>\n",
       "      <th>likes_end</th>\n",
       "      <th>tagCount</th>\n",
       "      <th>hoursTakenToTrend</th>\n",
       "      <th>trendingDaysDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--14w5SOEUs</td>\n",
       "      <td>Migos - Avalanche (Official Video)</td>\n",
       "      <td>MigosVEVO</td>\n",
       "      <td>Music</td>\n",
       "      <td>Migos|Avalanche|Quality|Control|Music/Motown|R...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-06-11 00:00:00+00:00</td>\n",
       "      <td>2021-06-15 00:00:00+00:00</td>\n",
       "      <td>122830</td>\n",
       "      <td>262692</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--2O86Z0hsM</td>\n",
       "      <td>MY TESLA PAYS FOR ITSELF</td>\n",
       "      <td>jf.okay</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-03-11 00:00:00+00:00</td>\n",
       "      <td>2022-03-15 00:00:00+00:00</td>\n",
       "      <td>16481</td>\n",
       "      <td>17290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--40TEbZ9Is</td>\n",
       "      <td>Supporting Actress in a Comedy: 73rd Emmys</td>\n",
       "      <td>Television Academy</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-09-21 00:00:00+00:00</td>\n",
       "      <td>2021-09-25 00:00:00+00:00</td>\n",
       "      <td>6299</td>\n",
       "      <td>8029</td>\n",
       "      <td>0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                       title  \\\n",
       "0  --14w5SOEUs          Migos - Avalanche (Official Video)   \n",
       "1  --2O86Z0hsM                    MY TESLA PAYS FOR ITSELF   \n",
       "2  --40TEbZ9Is  Supporting Actress in a Comedy: 73rd Emmys   \n",
       "\n",
       "         channelTitle     categoryId  \\\n",
       "0           MigosVEVO          Music   \n",
       "1             jf.okay  Entertainment   \n",
       "2  Television Academy  Entertainment   \n",
       "\n",
       "                                                tags  comments_disabled  \\\n",
       "0  Migos|Avalanche|Quality|Control|Music/Motown|R...              False   \n",
       "1                                                NaN              False   \n",
       "2                                                NaN              False   \n",
       "\n",
       "   ratings_disabled       trending_date_start         trending_date_end  \\\n",
       "0             False 2021-06-11 00:00:00+00:00 2021-06-15 00:00:00+00:00   \n",
       "1             False 2022-03-11 00:00:00+00:00 2022-03-15 00:00:00+00:00   \n",
       "2             False 2021-09-21 00:00:00+00:00 2021-09-25 00:00:00+00:00   \n",
       "\n",
       "   likes_start  likes_end  tagCount  hoursTakenToTrend  trendingDaysDuration  \n",
       "0       122830     262692         8                8.0                     4  \n",
       "1        16481      17290         0                0.7                     4  \n",
       "2         6299       8029         0               22.9                     4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataframe after all the changes\n",
    "\n",
    "modified_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14943dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34066, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying shape of Dataframe after all the changes\n",
    "\n",
    "modified_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d46ae201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                             object\n",
       "title                                object\n",
       "channelTitle                         object\n",
       "categoryId                           object\n",
       "tags                                 object\n",
       "comments_disabled                      bool\n",
       "ratings_disabled                       bool\n",
       "trending_date_start     datetime64[ns, UTC]\n",
       "trending_date_end       datetime64[ns, UTC]\n",
       "likes_start                           int64\n",
       "likes_end                             int64\n",
       "tagCount                              int64\n",
       "hoursTakenToTrend                   float64\n",
       "trendingDaysDuration                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the datatypes of the resultant Dataframe\n",
    "\n",
    "modified_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1ef1f",
   "metadata": {},
   "source": [
    "### Let's merge `modified_df` and `extracted_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7d6c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = pd.merge((modified_df, extracted_df), on = 'video_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b097506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying shape of final dataframe\n",
    "\n",
    "# final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bed5af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying final dataframe\n",
    "\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3fb24",
   "metadata": {},
   "source": [
    "`Duration` column is in ISO Date format. Let's convert it into seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dfa55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting time in 'Duration' column to Seconds\n",
    "\n",
    "#final_df['Duration'] = final_df['Duration'].apply(lambda x: isodate.parse_duration(x).total_seconds())\n",
    "\n",
    "# Validating the above changes\n",
    "\n",
    "#final_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3268c87",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "711fc680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'title', 'channelTitle', 'categoryId', 'tags',\n",
       "       'comments_disabled', 'ratings_disabled', 'trending_date_start',\n",
       "       'trending_date_end', 'likes_start', 'likes_end', 'tagCount',\n",
       "       'hoursTakenToTrend', 'trendingDaysDuration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the correlation between the numerical columns\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(data[['view_count', 'likes', 'dislikes', 'comment_count', 'daysTakenToTrend', 'tagCount']].corr(), linewidths=.5, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e3748",
   "metadata": {},
   "source": [
    "- `view_count` and `likes` are highly correlated. It is more likely that the video with more views has more likes.\n",
    "- `comment_count` and `likes` are relatively highly correlated when compared to `comment_count` and `views`.\n",
    "- `daysTakenToTrend` is not correlated to any feature. Which is interesting as it is impossible to correlate how many days the video will take to trend based on comment_count or dislikes or likes or view_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d02477",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### likes per view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae50dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking number of videos based on each Category\n",
    "\n",
    "plt.figure(figsize = (10, 4))\n",
    "sns.countplot(data['categoryId'], order = data['categoryId'].value_counts().sort_values(ascending = False).index)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88407a",
   "metadata": {},
   "source": [
    "There are more `Entertainment` videos and least type is `Nonprofits & Activism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e173a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(data = data, x = 'categoryId', y = 'likes',\n",
    "            order = data.groupby('categoryId')['likes'].mean().sort_values(ascending = False).index, ci = 0)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36e3b5",
   "metadata": {},
   "source": [
    "- `Pets & Animals` videos has most average likes and `New & Policts` videos has least average likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(data = data, x = 'categoryId', y = 'comment_count',\n",
    "            order = data.groupby('categoryId')['comment_count'].mean().sort_values(ascending = False).index, ci = 0)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9483b68e",
   "metadata": {},
   "source": [
    "`Music` videos has most average comment count and `Nonprofits & Activism` has least average comment count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(data = data, x = 'categoryId', y = 'daysTakenToTrend',\n",
    "            order = data.groupby('categoryId')['daysTakenToTrend'].mean().sort_values(ascending = False).index, ci = 0)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d9e2d",
   "metadata": {},
   "source": [
    "It is interesting to note that `News & Politics` videos take less time to trend and `Music`, `Comedy` and `Pets & Animals` videos take more time to trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['comments_disabled'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.countplot(data[data['ratings_disabled'] == True]['categoryId'], \n",
    "              order = data[data['ratings_disabled'] == True].groupby('categoryId')['ratings_disabled'].count().sort_values(ascending = False).index)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1812ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.countplot(data[data['tags'] == '[None]']['categoryId'], \n",
    "              order = data[data['tags'] == '[None]'].groupby('categoryId')['ratings_disabled'].count().sort_values(ascending = False).index)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract weekday from the trendingdate\n",
    "data['day'] = data['trending_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot number of trending videos for each day of the week\n",
    "sns.countplot(data['day'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f702e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily several videos trend but which video trends for the longest number of days will be the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify\n",
    "plt.figure(figsize = (15,4))\n",
    "sns.countplot(data = data, x = 'categoryId', hue = 'day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories that are taking minimum or moderate or maximum number of days to trend\n",
    "(data.groupby('categoryId')['daysTakenToTrend'].var().sort_values()).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd10b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['like/dislike ratio'] = round(data['likes']/data['dislikes'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify\n",
    "plt.figure(figsize = (8, 10))\n",
    "sns.histplot(data = data, x = 'like/dislike ratio', y = 'categoryId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5b91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296684f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
